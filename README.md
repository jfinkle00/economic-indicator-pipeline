# ğŸ“Š AWS Economic Indicator ETL Pipeline

> Automated cloud-native ETL pipeline for fetching, processing, and analyzing Federal Reserve economic data

[![AWS](https://img.shields.io/badge/AWS-Lambda%20%7C%20S3%20%7C%20RDS-FF9900?logo=amazon-aws)](https://aws.amazon.com/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16.3-4169E1?logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-success)](https://github.com/yourusername/economic-indicator-pipeline)

---

## ğŸ¯ Overview

A production-ready, fully automated ETL (Extract, Transform, Load) pipeline that fetches real-time economic indicator data from the Federal Reserve Economic Data (FRED) API, stores raw data in AWS S3, processes it, and loads it into an AWS RDS PostgreSQL database. The pipeline runs automatically on a daily schedule using AWS Lambda and CloudWatch Events.

**Perfect for:**
- Economic research and analysis
- Financial modeling and forecasting
- Data engineering portfolio projects
- Learning AWS cloud architecture
- Building data-driven applications

---

## âœ¨ Features

### Core Pipeline
- **ğŸ”„ Fully Automated**: Runs daily at 8:00 AM UTC via CloudWatch Events
- **â˜ï¸ Cloud-Native**: Built entirely on AWS serverless architecture
- **ğŸ’° Cost-Effective**: $0/month on AWS Free Tier, ~$17/month after
- **ğŸ“ˆ Real-Time Data**: Fetches latest economic indicators from FRED API
- **ğŸ—„ï¸ Structured Storage**: Organized PostgreSQL database with proper indexing
- **ğŸ“¦ Raw Data Backup**: All API responses stored in S3 for audit trail
- **ğŸ” Advanced Analytics**: Pre-built SQL queries for economic analysis
- **ğŸ“Š Production Metrics**: Complete logging and monitoring via CloudWatch
- **ğŸ›¡ï¸ Secure**: IAM roles with least-privilege access
- **ğŸ”§ Maintainable**: Modular Python code with clear separation of concerns

### Data Visualization & Analysis
- **ğŸ“Š Interactive Dashboards**: Plotly-based interactive HTML dashboards
- **ğŸ“ˆ Time Series Plots**: Professional matplotlib visualizations
- **ğŸ“‰ Trend Analysis**: Year-over-year change plots
- **ğŸ”— Correlation Heatmaps**: Visual correlation analysis between indicators
- **ğŸ“± Export Ready**: High-resolution PNG charts for reports and presentations

### Forecasting & Predictions
- **ğŸ”® ARIMA Forecasting**: Statistical time series forecasting with confidence intervals
- **ğŸ§  Prophet Models**: Facebook Prophet for robust trend forecasting
- **ğŸ¯ Auto-Selection**: Automatic model parameter optimization
- **ğŸ“ Backtesting**: Model validation with historical data
- **âš¡ 12-Month Forecasts**: Future economic indicator predictions

---

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FRED API      â”‚
                    â”‚ (Federal Reserve)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    AWS Lambda Function       â”‚
              â”‚  economic-indicator-etl      â”‚
              â”‚                              â”‚
              â”‚  â€¢ Fetch data from FRED      â”‚
              â”‚  â€¢ Store raw JSON in S3      â”‚
              â”‚  â€¢ Transform data            â”‚
              â”‚  â€¢ Load into PostgreSQL      â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚               â”‚
                     â–¼               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   AWS S3      â”‚  â”‚   AWS RDS          â”‚
         â”‚   Bucket      â”‚  â”‚   PostgreSQL 16.3  â”‚
         â”‚               â”‚  â”‚                    â”‚
         â”‚  raw/         â”‚  â”‚  â€¢ indicators      â”‚
         â”‚  â””â”€UNRATE/    â”‚  â”‚  â€¢ indicator_data  â”‚
         â”‚  â””â”€GDP/       â”‚  â”‚  â€¢ etl_logs        â”‚
         â”‚  â””â”€...        â”‚  â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–²
                 â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   CloudWatch Events     â”‚
      â”‚   cron(0 8 * * ? *)    â”‚
      â”‚   Daily at 8:00 AM UTC  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Economic Indicators Tracked

| Indicator | Description | Frequency | Series ID |
|-----------|-------------|-----------|-----------|
| ğŸ¢ **Unemployment Rate** | Civilian unemployment rate | Monthly | `UNRATE` |
| ğŸ’µ **Consumer Price Index** | CPI for all urban consumers (Inflation) | Monthly | `CPIAUCSL` |
| ğŸ“ˆ **GDP** | Gross Domestic Product | Quarterly | `GDP` |
| ğŸ’° **Federal Funds Rate** | Effective federal funds rate | Monthly | `FEDFUNDS` |
| ğŸ“Š **10-Year Treasury** | 10-Year Treasury constant maturity rate | Daily | `DGS10` |

---

## ğŸš€ Quick Start

### Prerequisites

- AWS Account ([Sign up for Free Tier](https://aws.amazon.com/free/))
- FRED API Key ([Get free key](https://fred.stlouisfed.org/docs/api/api_key.html))
- Python 3.11+
- AWS CLI configured
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/economic-indicator-pipeline.git
   cd economic-indicator-pipeline
   ```

2. **Set up Python environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your FRED API key and AWS credentials
   ```

4. **Deploy to AWS** (Optional - for automated pipeline)
   ```bash
   # Create RDS database
   aws rds create-db-instance \
       --db-instance-identifier economic-indicators-db \
       --db-instance-class db.t3.micro \
       --engine postgres \
       --master-username postgres \
       --master-user-password YourSecurePassword123! \
       --allocated-storage 20

   # Create S3 bucket
   aws s3 mb s3://economic-indicators-pipeline-your-initials

   # Deploy Lambda (see full deployment guide in docs/)
   ```

---

## ğŸ’» Usage

### Run Locally

```bash
# Activate environment
source venv/bin/activate

# Run the ETL pipeline
python lambda/lambda_function.py
```

**Expected Output:**
```
============================================================
Running Lambda function locally...
============================================================

Status Code: 200
Body: {'message': 'ETL pipeline executed successfully',
       'records_processed': 22,
       'execution_time_seconds': 1.58}
```

### Run on AWS

```bash
# Trigger Lambda function
aws lambda invoke \
  --function-name economic-indicator-etl \
  --payload '{}' \
  response.json

# View result
cat response.json
```

### Query the Data

```bash
# Connect to database
psql -h your-rds-endpoint.rds.amazonaws.com \
     -U postgres \
     -d economic_indicators

# Run queries
SELECT * FROM indicators;
```

**Or use Python:**
```python
import psycopg2
import pandas as pd

conn = psycopg2.connect(
    host="your-rds-endpoint.rds.amazonaws.com",
    database="economic_indicators",
    user="postgres",
    password="your-password"
)

df = pd.read_sql("SELECT * FROM indicator_data LIMIT 10", conn)
print(df)
```

### Generate Reports & Visualizations

**Quick summary:**
```bash
python generate_report.py --quick
```

**Full report with charts and forecasts:**
```bash
python generate_report.py --full
```

**Output includes:**
- Multi-indicator dashboard
- Interactive HTML dashboard
- Individual time series plots
- Year-over-year change analysis
- Correlation heatmap
- 12-month ARIMA forecasts

**Example output:**
```
Economic Indicators Report Generator
======================================================================

Connecting to database...
âœ“ Connected successfully
âœ“ Output directory: outputs/charts

Fetching indicator data...
  âœ“ Unemployment Rate: 1 data points
  âœ“ Consumer Price Index: 1 data points
  âœ“ 10-Year Treasury Rate: 19 data points

Generating visualizations...
Creating multi-indicator dashboard...
Saved: outputs/charts/multi_indicator_dashboard.png
Creating interactive dashboard...
Saved: outputs/charts/interactive_dashboard.html

Generating Forecasts (ARIMA)
======================================================================
Forecasting Unemployment Rate...
  âœ“ Unemployment Rate forecast completed
  Next 3 months forecast:
    2026-02: 4.42 (95% CI: 3.95 - 4.89)
    2026-03: 4.44 (95% CI: 3.87 - 5.01)
    2026-04: 4.46 (95% CI: 3.81 - 5.11)
```

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| **[USAGE_GUIDE.md](USAGE_GUIDE.md)** | Complete guide on how to use the pipeline |
| **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** | Detailed project documentation |
| **[sql/](sql/)** | Database schema and analysis queries |
| **[infrastructure/](infrastructure/)** | IAM policies and CloudWatch configs |

---

## ğŸ—‚ï¸ Project Structure

```
economic-indicator-pipeline/
â”‚
â”œâ”€â”€ lambda/                          # Lambda function source code
â”‚   â”œâ”€â”€ lambda_function.py          # Main ETL handler
â”‚   â”œâ”€â”€ fred_client.py              # FRED API client
â”‚   â”œâ”€â”€ s3_handler.py               # S3 operations
â”‚   â”œâ”€â”€ db_handler.py               # Database operations
â”‚   â””â”€â”€ config.py                   # Configuration
â”‚
â”œâ”€â”€ visualizations/                  # Data visualization modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ charts.py                   # Chart generation (matplotlib, plotly)
â”‚
â”œâ”€â”€ forecasting/                     # Forecasting modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models.py                   # ARIMA & Prophet models
â”‚
â”œâ”€â”€ sql/                             # SQL scripts
â”‚   â”œâ”€â”€ schema.sql                  # Database schema
â”‚   â”œâ”€â”€ queries.sql                 # Common queries
â”‚   â””â”€â”€ sample_analysis.sql         # Analytical queries
â”‚
â”œâ”€â”€ infrastructure/                  # Infrastructure configs
â”‚   â”œâ”€â”€ lambda_execution_role_policy.json
â”‚   â””â”€â”€ trust-policy.json
â”‚
â”œâ”€â”€ tests/                           # Test files
â”‚   â””â”€â”€ test_lambda.py
â”‚
â”œâ”€â”€ docs/                            # Additional documentation
â”‚
â”œâ”€â”€ outputs/                         # Generated reports & charts
â”‚   â””â”€â”€ charts/                     # Visualization outputs
â”‚
â”œâ”€â”€ initialize_database.py          # Database setup script
â”œâ”€â”€ verify_data.py                  # Data verification script
â”œâ”€â”€ generate_report.py              # Generate visualizations & forecasts
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.example                    # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ USAGE_GUIDE.md                  # Usage instructions
â”œâ”€â”€ PROJECT_SUMMARY.md              # Detailed documentation
â”œâ”€â”€ QUICK_START.md                  # 10-minute setup guide
â”œâ”€â”€ HOW_TO_USE.md                   # Simple usage reference
â””â”€â”€ LICENSE
```

---

## ğŸ“Š Performance & Metrics

### Latest Execution Stats
- **Status**: âœ… Success
- **Records Processed**: 22 data points
- **Execution Time**: 1.58 seconds
- **Data Retrieved**:
  - Unemployment Rate: 4.4%
  - 10-Year Treasury: 19 daily observations
  - CPI, Fed Funds, GDP: Latest monthly/quarterly data

### Database Statistics
- **Total Indicators**: 5
- **Total Data Points**: 22+
- **Update Frequency**: Daily (automated)
- **Data Retention**: Unlimited

---

## ğŸ’° Cost Breakdown

### Free Tier (First 12 months)
- **Lambda**: $0 (1M requests/month included)
- **S3**: $0 (5GB storage included)
- **RDS**: $0 (750 hours db.t3.micro included)
- **Total**: **$0/month** âœ…

### After Free Tier
- **RDS db.t3.micro**: ~$15/month
- **S3 Storage**: <$1/month
- **Lambda Executions**: <$1/month
- **Total**: **~$17/month**

**Cost Optimization Tips:**
- Stop RDS when not in use: Save $15/month
- Delete old S3 data: Reduce storage costs
- Use RDS snapshots: Cheaper than running instance

---

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file with:

```bash
# FRED API Configuration
FRED_API_KEY=your_fred_api_key_here

# AWS Configuration
AWS_REGION=us-east-1
S3_BUCKET_NAME=economic-indicators-pipeline-your-initials

# Database Configuration
DB_HOST=your-rds-endpoint.rds.amazonaws.com
DB_NAME=economic_indicators
DB_USER=postgres
DB_PASSWORD=your_secure_password
DB_PORT=5432
```

### Adding New Indicators

1. Add to database:
   ```sql
   INSERT INTO indicators (series_id, title, units, frequency, seasonal_adjustment)
   VALUES ('HOUST', 'Housing Starts', 'Thousands', 'Monthly', 'Seasonally Adjusted');
   ```

2. Update Lambda code:
   ```python
   # In lambda/lambda_function.py
   INDICATORS = ['UNRATE', 'CPIAUCSL', 'GDP', 'FEDFUNDS', 'DGS10', 'HOUST']
   ```

3. Redeploy Lambda function

---

## ğŸ“ Skills Demonstrated

### Cloud Engineering (AWS)
- âœ… Lambda serverless functions
- âœ… S3 object storage and lifecycle policies
- âœ… RDS managed PostgreSQL databases
- âœ… IAM roles and security policies
- âœ… CloudWatch Events scheduling
- âœ… CloudWatch Logs monitoring
- âœ… AWS CLI automation

### Data Engineering
- âœ… ETL pipeline architecture
- âœ… REST API integration (FRED)
- âœ… Data extraction and transformation
- âœ… Error handling and retry logic
- âœ… Data quality validation
- âœ… Automated scheduling
- âœ… Performance optimization

### Database (PostgreSQL)
- âœ… Schema design with normalization
- âœ… Indexing strategies
- âœ… UPSERT operations (INSERT ON CONFLICT)
- âœ… Complex analytical queries
- âœ… Window functions and CTEs
- âœ… Query optimization

### Python Development
- âœ… Object-oriented programming
- âœ… Modular architecture
- âœ… Exception handling
- âœ… Environment management
- âœ… Third-party integrations (boto3, psycopg2, requests)
- âœ… PEP 8 coding standards

---

## ğŸ§ª Testing

### Run Tests Locally

```bash
# Activate environment
source venv/bin/activate

# Test Lambda function
python lambda/lambda_function.py

# Verify data loaded
python verify_data.py

# Run unit tests (if available)
pytest tests/
```

### Verify AWS Deployment

```bash
# Test Lambda in AWS
aws lambda invoke \
  --function-name economic-indicator-etl \
  --payload '{}' \
  response.json

# Check CloudWatch logs
# AWS Console â†’ CloudWatch â†’ Logs â†’ /aws/lambda/economic-indicator-etl

# Verify data in RDS
python verify_data.py
```

---

## ğŸ“ˆ Sample Queries

### Get Latest Economic Snapshot

```sql
SELECT
    i.series_id,
    i.title,
    d.value,
    d.observation_date,
    i.units
FROM indicators i
LEFT JOIN LATERAL (
    SELECT value, observation_date
    FROM indicator_data
    WHERE indicator_id = i.indicator_id
    ORDER BY observation_date DESC
    LIMIT 1
) d ON true
ORDER BY i.series_id;
```

### Analyze Unemployment Trends

```sql
SELECT
    observation_date,
    value as unemployment_rate,
    AVG(value) OVER (
        ORDER BY observation_date
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) as three_month_avg
FROM indicator_data
WHERE indicator_id = (
    SELECT indicator_id FROM indicators WHERE series_id = 'UNRATE'
)
ORDER BY observation_date DESC
LIMIT 12;
```

More queries available in [`sql/sample_analysis.sql`](sql/sample_analysis.sql)

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Pipeline not running automatically:**
```bash
# Check CloudWatch Event Rule
aws events list-rules --name-prefix economic-indicator

# Verify Lambda has permission
aws lambda get-policy --function-name economic-indicator-etl
```

**Database connection failed:**
```bash
# Check RDS status
aws rds describe-db-instances \
  --db-instance-identifier economic-indicators-db \
  --query "DBInstances[0].DBInstanceStatus"

# Verify security group allows connection
```

**Lambda timeout:**
```bash
# Increase timeout to 600 seconds
aws lambda update-function-configuration \
  --function-name economic-indicator-etl \
  --timeout 600
```

See [USAGE_GUIDE.md](USAGE_GUIDE.md) for more troubleshooting tips.

---

## ğŸš€ Implemented Features & Future Enhancements

### âœ… Completed
- [x] Data visualization dashboard (matplotlib, Plotly)
- [x] Forecasting models (ARIMA, Prophet)
- [x] Interactive HTML dashboards
- [x] Automated report generation
- [x] Year-over-year analysis
- [x] Correlation analysis

### ğŸ¯ Planned Enhancements
- [ ] Real-time Streamlit dashboard
- [ ] SNS alerts for pipeline failures
- [ ] REST API with API Gateway
- [ ] Add more economic indicators (Housing, Employment)
- [ ] Enhanced data quality checks
- [ ] CI/CD pipeline with GitHub Actions
- [ ] Infrastructure as Code (Terraform)
- [ ] Comprehensive testing suite
- [ ] Jupyter notebook examples
- [ ] Email reports automation
- [ ] Machine learning anomaly detection

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Jason Finkle**

- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## ğŸ™ Acknowledgments

- [Federal Reserve Economic Data (FRED)](https://fred.stlouisfed.org/) for providing free economic data API
- [AWS Free Tier](https://aws.amazon.com/free/) for cloud infrastructure
- Inspired by real-world data engineering best practices

---

## ğŸ“š Resources

- [FRED API Documentation](https://fred.stlouisfed.org/docs/api/)
- [AWS Lambda Documentation](https://docs.aws.amazon.com/lambda/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [boto3 Documentation](https://boto3.amazonaws.com/v1/documentation/)

---

## â­ Star This Repository

If you found this project useful, please consider giving it a star! It helps others discover the project.

---

<div align="center">

**Built with â¤ï¸ using AWS, Python, and PostgreSQL**

[Report Bug](https://github.com/yourusername/economic-indicator-pipeline/issues) Â· [Request Feature](https://github.com/yourusername/economic-indicator-pipeline/issues)

</div>
